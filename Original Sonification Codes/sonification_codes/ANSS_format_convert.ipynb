{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "''' convert from ANSS to our file format.\n",
    "\n",
    "US:     \n",
    "ID time latitude longitude depth_km mb ms mw\n",
    "1st_np_strike 1st_np_dip 1st_np_rake 2nd_np_strike second_np_dip second_np_rake\n",
    "data_strings = [\"event_id\", \"time\", \"lat\", \"lon\", \"depth\", \"body_mag\", \"ms\", \"moment_mag\", \"1st_np_strike\",\n",
    "                   \"1st_np_dip\", \"1st_np_rake\", \"2nd_np_strike\", \"second_np_dip\", \"second_np_rake\"]\n",
    "\n",
    "\n",
    "ANSS:\n",
    "[0]       [1]       [2]        [3]    [4]        [5]      [6]         [7]  [8]       [9]  [10]    [11]\n",
    "DateTime, Latitude, Longitude, Depth, Magnitude, MagType, NbStations, Gap, Distance, RMS, Source, EventID\n",
    "2004/04/22 16:13:02.25,34.8040,-97.6770,5.00,2.90,ML,10,,,0.00,TUL,200404224070\n",
    "        \n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "    \n",
    "#input_file = \".quakes/ok_frack/OK_12yrs_ANSS_CSV.txt\"\n",
    "#input_file = \"../quakes/ok_frack/OKcatalog_minM1p5.csv\"\n",
    "#input_file = \"../quakes/ok_frack/data.cvs.txt\"\n",
    "#input_file = \"../quakes/convo_chile_17yrs/chile_data.csv.txt\"\n",
    "# Leif's catalog, modified from ANSS?\n",
    "# input_file = \"../quakes/steamboat/ForAnna_EQ_2.csv\"\n",
    "input_file = \"../quakes/kilauea_2018/filtered_catalog.csv\"\n",
    "#input_file = \"../quakes/kilauea_2018/EQ_Eruption_Catalog_4_1_2018_8_30_2018_HVO.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def convert_date_to_millis(time):\n",
    "# time comes in different formats! Look at the way it's listed in data file and mirror that here\n",
    "    # format with a space, no 'T': \n",
    "    #utc_time = datetime.strptime(time, '%Y/%m/%d %H:%M:%S.%f')\n",
    "    # another format with a T\n",
    "#     utc_time = datetime.strptime(time, '%y-%m-%d %H:%M:%S')\n",
    "    utc_time = datetime.strptime(time, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    # THIS IS the first second of January 1, 1970 (value=0): \n",
    "    epoch = datetime.utcfromtimestamp(0)\n",
    "\n",
    "    milliseconds = (utc_time - epoch).total_seconds() * 1000.0\n",
    "    return milliseconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4\n",
      "19380\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(input_file,dtype={'time':str})\n",
    "print(max(data.mag))\n",
    "#data['time'].values.tolist()\n",
    "#data['time'].str.strip('()').astype(str)\n",
    "\n",
    "data.time = pd.to_datetime(data.time)\n",
    "\n",
    "#print(max(data.lat),min(data.lat),max(data.lon),min(data.lon))\n",
    "\n",
    "print(len(data.time[data.mag>2.3]))\n",
    "\n",
    "# data.plot(x = 'time', y = 'mag', style = '.', figsize = (15,8),legend=False, color = 'k')\n",
    "# plt.ylabel('Magnitude')\n",
    "# plt.savefig('/Users/annabarth/Dropbox/EQ_timeseries.png')\n",
    "\n",
    "#plt.plot(data.time[0:100], data.mag[0:100], 'ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'time_ms': []})\n",
    "# for time in data.time:\n",
    "#     #data.new_time[] = convert_date_to_millis(time)\n",
    "#     df = df.append({'time_ms': convert_date_to_millis(time)}, ignore_index=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([16082], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "start_idx = data.index[data.id == 'hv70352941']\n",
    "end_idx = data.index[data.id == 'hv70359181']\n",
    "print(end_idx)\n",
    "start_idx = 15492\n",
    "end_idx =16082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all = pd.concat([data, df], axis = 1)\n",
    "# print(data_all.head())\n",
    "# data_all.drop(labels='time', axis=1,inplace = True)\n",
    "\n",
    "# data_all.head()\n",
    "# plt.figure(figsize = (15,7))\n",
    "# plt.plot(data_all.time_ms,data_all.mag,'o')\n",
    "\n",
    "# print(min(data_all.mag))\n",
    "# #np.savetxt('Steamboat_EQcat.txt', data_all.values,fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # STEAMBOAT write WITH key:value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# mag_threshold = 0\n",
    "\n",
    "# # write a vector of lat and lon\n",
    "# lats = []\n",
    "# lons = []\n",
    "# times = []\n",
    "# mags = []\n",
    "\n",
    "# count=0\n",
    "# for line in f:\n",
    "#     if count > 0:\n",
    "#         parts = line.split(\",\")\n",
    "#  #       print(parts[4])\n",
    "#         if float(parts[5]) >= mag_threshold:\n",
    "\n",
    "#             #time_string = parts[3] + \"-\" + parts[4] + \"-\" + parts[5] + \"T\" + parts[6] + \":\" + parts[7] + \":\" + parts[8] + \"Z\"\n",
    "#             #time = convert_time(time_string)\n",
    "\n",
    "#             time = convert_date_to_millis(parts[1])\n",
    "\n",
    "#             new_line = (\"ID:\" + parts[0].strip() + \"\\t\" \n",
    "#                 \"time:\" + str(time) + \"\\t\"\n",
    "#                 \"lat:\" + parts[2] + \"\\t\"\n",
    "#                 \"lon:\" + parts[3] + \"\\t\" \n",
    "#                 \"depth:\" + parts[4] + \"\\t\"\n",
    "#                 \"mag:\" + parts[5] + \"\\n\")\n",
    "\n",
    "#             times.append(time)\n",
    "#             lats.append(parts[2])\n",
    "#             lons.append(parts[3])\n",
    "#             mags.append(parts[5])\n",
    "\n",
    "#             f_out.write(str(new_line))\n",
    "#     count += 1\n",
    "\n",
    "# f.close()\n",
    "# f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def convert_millis_to_date(ms):\n",
    "    \n",
    "    return datetime.utcfromtimestamp(ms/1000.0).strftime('%Y/%m/%d %H:%M:%S.%f')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "f = open(input_file, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# for Leif's file of Kilauea earthquakes... (modified from ?)\n",
    "line=f.readline()\n",
    "print(line)\n",
    "parts = line.split(\",\")\n",
    "print(parts)\n",
    "print(\"p6 [id]: \" + parts[6] + \":\")\n",
    "print(\"p6: \" + parts[6].strip() )\n",
    "# LEIF's: \n",
    "# time,latitude,longitude,depth,mag,dist from Halemaumau (degrees),id,type,horizontalError,depthError,magError\n",
    "\n",
    "# ANSS:\n",
    "# [0]       [1]       [2]        [3]    [4]        [5]      [6]         [7]  [8]       [9]  [10]    [11]\n",
    "# DateTime, Latitude, Longitude, Depth, Magnitude, MagType, NbStations, Gap, Distance, RMS, Source, EventID\n",
    "# 2004/04/22 16:13:02.25,34.8040,-97.6770,5.00,2.90,ML,10,,,0.00,TUL,200404224070\n",
    "\n",
    "# OURS: \n",
    "# data_strings = [\"event_id\", \"time\", \"lat\", \"lon\", \"depth\", \"body_mag\", \"ms\", \"moment_mag\", \"1st_np_strike\",\n",
    "#                   \"1st_np_dip\", \"1st_np_rake\", \"2nd_np_strike\", \"second_np_dip\", \"second_np_rake\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "f = open(input_file, 'r')\n",
    "f_out = open(input_file + \".eq_format_one_cycle.txt\", 'w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for Leif's or other custom catalog:\n",
    "# write WITH key:value\n",
    "\n",
    "mag_threshold = 1.5\n",
    "# 2.3 for zoom (many cycles) \n",
    "# 2.5 for full\n",
    "# 1.5 for zoom one cycle\n",
    "\n",
    "# write a vector of lat and lon\n",
    "lats = []\n",
    "lons = []\n",
    "times = []\n",
    "mags = []\n",
    "\n",
    "count=0\n",
    "for line in f:\n",
    "    if count > start_idx and count < end_idx:\n",
    "        parts = line.split(\",\")\n",
    " #       print(parts[4])\n",
    "        if float(parts[4]) >= mag_threshold:\n",
    "\n",
    "            #time_string = parts[3] + \"-\" + parts[4] + \"-\" + parts[5] + \"T\" + parts[6] + \":\" + parts[7] + \":\" + parts[8] + \"Z\"\n",
    "            #time = convert_time(time_string)\n",
    "\n",
    "            time = convert_date_to_millis(parts[0])\n",
    "\n",
    "            new_line = (\"ID:\" + parts[6].strip() + \"\\t\" \n",
    "                \"time:\" + str(time) + \"\\t\"\n",
    "                \"lat:\" + parts[1] + \"\\t\"\n",
    "                \"lon:\" + parts[2] + \"\\t\" \n",
    "                \"depth:\" + parts[3] + \"\\t\"\n",
    "                \"mag:\" + parts[4] + \"\\n\")\n",
    "\n",
    "            times.append(time)\n",
    "            lats.append(parts[1])\n",
    "            lons.append(parts[2])\n",
    "            mags.append(parts[4])\n",
    "\n",
    "            f_out.write(str(new_line))\n",
    "    count += 1\n",
    "\n",
    "f.close()\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(len(lats))\n",
    "print('lats: ', sorted(lats)[0], sorted(lats)[-1])\n",
    "print('lons: ', min(lons), max(lons))\n",
    "print('mags: ', min(mags), max(mags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(times,mags)  # THIs is weird.. not how it looks in the sound.. \n",
    "#plt.hist(mags)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for Leif's or other custom catalog:\n",
    "# write WITHOUT key:value\n",
    "\n",
    "for line in f:\n",
    "    parts = line.split(\",\")\n",
    "        \n",
    "    #time = convert_time(parts[0]) \n",
    "    time = convert_date_to_millis(parts[0])\n",
    "    # event ID: \n",
    "    #parts[6] = parts[6].strip()\n",
    "    new_line = parts[6].strip() + \"\\t\" + str(time) + \"\\t\" + parts[1] + \"\\t\" + parts[2] + \"\\t\" + parts[3] + \"\\t\" + \"0.0\" + \"\\t\" + \"0.0\" + \"\\t\" + parts[4] + \"\\t\" + \"0.0\" + \"\\t\" + \"0.0\" + \"\\t\" + \"0.0\" + \"\\t\" + \"0.0\" + \"\\t\" + \"0.0\" + \"\\t\" + \"0.0\" + \"\\n\"\n",
    "    \n",
    "    f_out.write(str(new_line))\n",
    "\n",
    "\n",
    "f.close()\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# FOR ANSS catalogs: (pre Key:Value format !)\n",
    "\n",
    "do_it = True\n",
    "\n",
    "for line in f:\n",
    "    parts = line.split(\",\")\n",
    "        \n",
    "    time = convert_time(parts[0])\n",
    "\n",
    "    parts[11] = parts[11].strip()\n",
    "    \n",
    "    if do_it:\n",
    "        print parts\n",
    "        print \"p11:\" + parts[11] + \":\"\n",
    "        print \"p11:\" + parts[11].strip() + \":\"\n",
    "        do_it = False\n",
    "    new_line = parts[11].strip() + \"\\t\" + str(time) + \"\\t\" + parts[1] + \"\\t\" + parts[2] + \"\\t\" + parts[3] + \"\\t\" + \"0.0\" + \"\\t\" + \"0.0\" + \"\\t\" + parts[4] + \"\\t\" + \"0.0\" + \"\\t\" + \"0.0\" + \"\\t\" + \"0.0\" + \"\\t\" + \"0.0\" + \"\\t\" + \"0.0\" + \"\\t\" + \"0.0\" + \"\\n\"\n",
    "    \n",
    "    f_out.write(str(new_line))\n",
    "\n",
    "\n",
    "f.close()\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# use this to create millisecond values for movie_start_time in movie_info.txt\n",
    "convert_date_to_millis(\"1984/01/01 00:00:00.00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# use this to convert millis back to date\n",
    "convert_millis_to_date(441763200000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
