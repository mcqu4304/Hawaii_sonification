{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loop over waveforms from each station\n",
    "\n",
    "### import the catalog\n",
    "\n",
    "### 1) for list of stations that may be used\n",
    "### 2) find how many events have data at each station\n",
    "### 3) test for clipping\n",
    "### 4) write out lists results for each event and station:  0=none, 1=good, 2=clipped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import obspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DirCatalog = '/home/ben/data/Kilauea/'\n",
    "cat_orig = 'EQ_Eruption_Catalog_4_1_2018_8_30_2018_HVO.csv'\n",
    "\n",
    "FOV='zoomOnecycle_v2'\n",
    "\n",
    "if FOV=='big':\n",
    "    station_name = 'STCD'\n",
    "    catname_pkl = './cat_STDC_bigview.pkl'  \n",
    "    \n",
    "if FOV=='zoom':\n",
    "    station_name = 'PUHI'\n",
    "    catname_pkl = './catalogs/cat_PUHI_zoomview.pkl'  \n",
    "\n",
    "if FOV=='zoomOnecycle_v2':\n",
    "    station_name = 'PUHI'\n",
    "    catname_pkl = './catalogs/cat_PUHI_zoomOnecycle_v2.pkl'  \n",
    "    \n",
    "DataDir = '/home/ben/data/Kilauea/waveforms_' + station_name + '/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The catalog has events: 41328\n",
      "Index(['time', 'latitude', 'longitude', 'depth', 'mag',\n",
      "       'dist from Halemaumau (degrees)', 'id', 'type', 'horizontalError',\n",
      "       'depthError', 'magError'],\n",
      "      dtype='object')\n",
      "0    hv70068046\n",
      "1    hv70068071\n",
      "2    hv70068076\n",
      "3    hv70068091\n",
      "4    hv70068096\n",
      "Name: id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "cat = pd.read_csv(DirCatalog+cat_orig,header=0, encoding='utf_8')\n",
    "#date_time_str_list = catalog.iloc[:,0].tolist()\n",
    "print('The catalog has events: ' + str(cat.shape[0]))\n",
    "print(cat.columns)\n",
    "\n",
    "print(cat.id[0:5])\n",
    "\n",
    "#names_vec = ['time','lat','lon','dep','mag','degrees','id', 'type', 'error1', 'error2', 'error3','valid']\n",
    "#tab = pd.read_csv(DirCatalog + FileCatalog, header=None, delimiter=',', names=names_vec)\n",
    "        \n",
    "\n",
    "#print('The catalog is a dataframe of size ' + str(tab.shape))\n",
    "#print('I will assume (correct me if I\\'m wrong) that the fields are:\\n\\t year\\n\\t month\\n\\t day\\n\\t hour\\n\\t minute\\n\\t seconds\\n\\t latitude\\n\\t longitude\\n\\t depth\\n\\t magnitude\\n\\t id')\n",
    "#print('There are ' + str(len(tab['time'])) + ' events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of events, pre-filt: 41328\n"
     ]
    }
   ],
   "source": [
    "# NEED TO FILTER EVENTS BY VIEW AND TIME WINDOW FOR ZOOM IF MAKING ZOOM ! \n",
    "print('number of events, pre-filt: ' + str(len(cat)))\n",
    "\n",
    "starttimes = np.zeros(len(cat['time']))\n",
    "for k in range(0,len(cat['time'])-1):\n",
    "    starttimes[k] = obspy.UTCDateTime(cat['time'][k]).timestamp\n",
    "    \n",
    "cat['starttimes'] = pd.Series(starttimes) # and put it in the dataframe\n",
    "cat = cat[cat.starttimes>0.0]\n",
    "\n",
    "cat = cat.sort_values(by=['starttimes'])\n",
    "# And reset indices\n",
    "cat = cat.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of events, pre-filt: 41327\n",
      "2018-06-02T03:43:36.880Z\n",
      "2018-06-04T07:50:59.940Z\n",
      "number of events, post_time filt: 579\n"
     ]
    }
   ],
   "source": [
    "# trial and error !\n",
    "print('number of events, pre-filt: ' + str(len(cat)))\n",
    "\n",
    "# start_time = pd.Timestamp(2018,6,2,3,43,36,0)\n",
    "# print(start_time)\n",
    "# print(cat.columns)\n",
    "# start_idx = cat.time[cat.time == start_time]\n",
    "# print(start_idx)\n",
    "# print(type(start_time))\n",
    "# print(type(cat.time[0]))\n",
    "\n",
    "#start_day = pd.to_datetime('2018-05-31')\n",
    "\n",
    "#  2018,6,2,3,43,36,0\n",
    "\n",
    "#  2018,6,4,7,50,59,0\n",
    "\n",
    "\n",
    "start_day = pd.to_datetime('2018-06-02')\n",
    "#print('start day = ' + str(start_day))\n",
    "print(cat.time[5354])\n",
    "\n",
    "2018,6,4,7,50,59,0\n",
    "#end_day = pd.to_datetime('2018-08-08')\n",
    "end_day = pd.to_datetime('2018-06-04')\n",
    "#print('end day = ' + str(end_day))\n",
    "print(cat.time[5933])\n",
    "\n",
    "#pd.to_datetime(tab.time[findthis])\n",
    "#obspy.UTCDateTime(tab['time'][k]).timestamp\n",
    "\n",
    "cat = cat[5354:5933]\n",
    "\n",
    "print('number of events, post_time filt: ' + str(len(cat)))\n",
    "\n",
    "# df[df.Length > 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of events, post_area filt: 523\n"
     ]
    }
   ],
   "source": [
    "# FILTER BY AREA ! \n",
    "\n",
    "# by lat,lon ! \n",
    "# lat_max = 19.45502\n",
    "# lat_min = 19.36596 \n",
    "# lon_max = -155.20426 \n",
    "# lon_min = -155.32703\n",
    "\n",
    "lat_min = 19.365964975838335\n",
    "lat_max =  19.45502134426063\n",
    "lon_min = -155.3270365580801\n",
    "lon_max = -155.20426605913994\n",
    "\n",
    "cat = cat[cat.latitude>=lat_min]\n",
    "cat = cat[cat.latitude<=lat_max]\n",
    "cat = cat[cat.longitude>=lon_min]\n",
    "cat = cat[cat.longitude<=lon_max]\n",
    "\n",
    "print('number of events, post_area filt: ' + str(len(cat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "41279\n",
      "['/home/ben/data/Kilauea/waveforms_PUHI/hv70476572.txt', '/home/ben/data/Kilauea/waveforms_PUHI/hv70218497.txt', '/home/ben/data/Kilauea/waveforms_PUHI/hv70478067.txt', '/home/ben/data/Kilauea/waveforms_PUHI/hv70409077.txt', '/home/ben/data/Kilauea/waveforms_PUHI/hv70318106.txt']\n",
      "['hv70476572', 'hv70218497', 'hv70478067', 'hv70409077', 'hv70318106']\n"
     ]
    }
   ],
   "source": [
    "# how many events in the data directory?  \n",
    "evfilelist_f = glob.glob(DataDir+'*')\n",
    "print(type(evfilelist_f))\n",
    "print(len(evfilelist_f))\n",
    "print(evfilelist_f[0:5])\n",
    "\n",
    "evfilelist = []\n",
    "for ev in evfilelist_f:\n",
    "    ev = ev.split('/')[6] \n",
    "    ev = ev.strip('.txt')\n",
    "    evfilelist.append(ev)\n",
    "\n",
    "print(evfilelist[0:5])\n",
    "\n",
    "evstalist = pd.DataFrame({'id':evfilelist})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N events in catalog: 523\n",
      "N events at station PUHI: 41279\n"
     ]
    }
   ],
   "source": [
    "## Go through catalog and ask if the event is in the evlist, \n",
    "## if not, remove it from the dataframe\n",
    "## then pickle it ! \n",
    "print('N events in catalog: '+str(len(cat)))\n",
    "print('N events at station '+ station_name+': '+str(len(evfilelist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523\n",
      "Index(['index', 'time', 'latitude', 'longitude', 'depth', 'mag',\n",
      "       'dist from Halemaumau (degrees)', 'id', 'type', 'horizontalError',\n",
      "       'depthError', 'magError', 'starttimes'],\n",
      "      dtype='object')\n",
      "Index(['index', 'time', 'lat', 'lon', 'depth', 'mag',\n",
      "       'dist from Halemaumau (degrees)', 'id', 'type', 'horizontalError',\n",
      "       'depthError', 'magError', 'starttimes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# MERGE catalog and list, getting rid of all events that are not in the list ! \n",
    "#pd.merge(adf, bdf,how='inner', on='x1')\n",
    "\n",
    "cat_PUHI = pd.merge(cat,evstalist,how='inner',on='id')\n",
    "print(len(cat_PUHI))\n",
    "print(cat_PUHI.columns)\n",
    "#cat.rename(columns = {'y':'year'})\n",
    "cat_PUHI = cat_PUHI.rename(columns = {'latitude':'lat','longitude':'lon'})\n",
    "print(cat_PUHI.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_PUHI.to_pickle(catname_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./catalogs/cat_PUHI_zoomOnecycle_v2.pkl\n"
     ]
    }
   ],
   "source": [
    "print(catname_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
